{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ZipFile.close of <zipfile.ZipFile filename='tiny-imagenet-200.zip' mode='r'>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import zipfile as zf\n",
    "#files = zf.ZipFile(\"tiny-imagenet-200.zip\", 'r')\n",
    "#files.extractall()\n",
    "#files.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "\n",
    "import vgg\n",
    "import resnet\n",
    "import googlenet\n",
    "import alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = 'tiny-imagenet-200/'\n",
    "\n",
    "num_workers = {\n",
    "    'train' : 100,\n",
    "    'val'   : 0,\n",
    "    'test'  : 0\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val','test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=100,\n",
    "                                             shuffle=True,num_workers=num_workers[x])\n",
    "              for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "images, labels = next(iter(dataloaders['train']))\n",
    "print(labels)\n",
    "grid_img = make_grid(images[:4], nrow=4)\n",
    "imshow(grid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "net = alexnet.AlexNet()     # Create the network instance.\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "# We use stochastic gradient descent (SGD) as optimizer.\n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    99] avg mini-batch loss: 6.905\n",
      "[epoch: 0, i:   199] avg mini-batch loss: 6.896\n",
      "[epoch: 0, i:   299] avg mini-batch loss: 6.879\n",
      "[epoch: 0, i:   399] avg mini-batch loss: 6.344\n",
      "[epoch: 0, i:   499] avg mini-batch loss: 5.517\n",
      "[epoch: 0, i:   599] avg mini-batch loss: 5.454\n",
      "[epoch: 0, i:   699] avg mini-batch loss: 5.427\n",
      "[epoch: 0, i:   799] avg mini-batch loss: 5.406\n",
      "[epoch: 0, i:   899] avg mini-batch loss: 5.398\n",
      "[epoch: 0, i:   999] avg mini-batch loss: 5.388\n",
      "[epoch: 1, i:    99] avg mini-batch loss: 5.387\n",
      "[epoch: 1, i:   199] avg mini-batch loss: 5.379\n",
      "[epoch: 1, i:   299] avg mini-batch loss: 5.371\n",
      "[epoch: 1, i:   399] avg mini-batch loss: 5.369\n",
      "[epoch: 1, i:   499] avg mini-batch loss: 5.371\n",
      "[epoch: 1, i:   599] avg mini-batch loss: 5.364\n",
      "[epoch: 1, i:   699] avg mini-batch loss: 5.361\n",
      "[epoch: 1, i:   799] avg mini-batch loss: 5.357\n",
      "[epoch: 1, i:   899] avg mini-batch loss: 5.353\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 5.360\n",
      "[epoch: 2, i:    99] avg mini-batch loss: 5.353\n",
      "[epoch: 2, i:   199] avg mini-batch loss: 5.350\n",
      "[epoch: 2, i:   299] avg mini-batch loss: 5.348\n",
      "[epoch: 2, i:   399] avg mini-batch loss: 5.344\n",
      "[epoch: 2, i:   499] avg mini-batch loss: 5.348\n",
      "[epoch: 2, i:   599] avg mini-batch loss: 5.346\n",
      "[epoch: 2, i:   699] avg mini-batch loss: 5.341\n",
      "[epoch: 2, i:   799] avg mini-batch loss: 5.347\n",
      "[epoch: 2, i:   899] avg mini-batch loss: 5.345\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 5.339\n",
      "[epoch: 3, i:    99] avg mini-batch loss: 5.340\n",
      "[epoch: 3, i:   199] avg mini-batch loss: 5.342\n",
      "[epoch: 3, i:   299] avg mini-batch loss: 5.335\n",
      "[epoch: 3, i:   399] avg mini-batch loss: 5.332\n",
      "[epoch: 3, i:   499] avg mini-batch loss: 5.333\n",
      "[epoch: 3, i:   599] avg mini-batch loss: 5.334\n",
      "[epoch: 3, i:   699] avg mini-batch loss: 5.329\n",
      "[epoch: 3, i:   799] avg mini-batch loss: 5.322\n",
      "[epoch: 3, i:   899] avg mini-batch loss: 5.308\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 5.274\n",
      "[epoch: 4, i:    99] avg mini-batch loss: 5.216\n",
      "[epoch: 4, i:   199] avg mini-batch loss: 5.170\n",
      "[epoch: 4, i:   299] avg mini-batch loss: 5.154\n",
      "[epoch: 4, i:   399] avg mini-batch loss: 5.136\n",
      "[epoch: 4, i:   499] avg mini-batch loss: 5.134\n",
      "[epoch: 4, i:   599] avg mini-batch loss: 5.134\n",
      "[epoch: 4, i:   699] avg mini-batch loss: 5.116\n",
      "[epoch: 4, i:   799] avg mini-batch loss: 5.116\n",
      "[epoch: 4, i:   899] avg mini-batch loss: 5.123\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 5.101\n",
      "[epoch: 5, i:    99] avg mini-batch loss: 5.097\n",
      "[epoch: 5, i:   199] avg mini-batch loss: 5.083\n",
      "[epoch: 5, i:   299] avg mini-batch loss: 5.102\n",
      "[epoch: 5, i:   399] avg mini-batch loss: 5.082\n",
      "[epoch: 5, i:   499] avg mini-batch loss: 5.083\n",
      "[epoch: 5, i:   599] avg mini-batch loss: 5.065\n",
      "[epoch: 5, i:   699] avg mini-batch loss: 5.075\n",
      "[epoch: 5, i:   799] avg mini-batch loss: 5.062\n",
      "[epoch: 5, i:   899] avg mini-batch loss: 5.046\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 5.048\n",
      "[epoch: 6, i:    99] avg mini-batch loss: 5.034\n",
      "[epoch: 6, i:   199] avg mini-batch loss: 5.030\n",
      "[epoch: 6, i:   299] avg mini-batch loss: 5.017\n",
      "[epoch: 6, i:   399] avg mini-batch loss: 5.016\n",
      "[epoch: 6, i:   499] avg mini-batch loss: 5.004\n",
      "[epoch: 6, i:   599] avg mini-batch loss: 4.989\n",
      "[epoch: 6, i:   699] avg mini-batch loss: 4.977\n",
      "[epoch: 6, i:   799] avg mini-batch loss: 4.975\n",
      "[epoch: 6, i:   899] avg mini-batch loss: 4.931\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 4.937\n",
      "[epoch: 7, i:    99] avg mini-batch loss: 4.913\n",
      "[epoch: 7, i:   199] avg mini-batch loss: 4.914\n",
      "[epoch: 7, i:   299] avg mini-batch loss: 4.889\n",
      "[epoch: 7, i:   399] avg mini-batch loss: 4.877\n",
      "[epoch: 7, i:   499] avg mini-batch loss: 4.863\n",
      "[epoch: 7, i:   599] avg mini-batch loss: 4.853\n",
      "[epoch: 7, i:   699] avg mini-batch loss: 4.838\n",
      "[epoch: 7, i:   799] avg mini-batch loss: 4.828\n",
      "[epoch: 7, i:   899] avg mini-batch loss: 4.807\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 4.799\n",
      "[epoch: 8, i:    99] avg mini-batch loss: 4.755\n",
      "[epoch: 8, i:   199] avg mini-batch loss: 4.748\n",
      "[epoch: 8, i:   299] avg mini-batch loss: 4.745\n",
      "[epoch: 8, i:   399] avg mini-batch loss: 4.699\n",
      "[epoch: 8, i:   499] avg mini-batch loss: 4.702\n",
      "[epoch: 8, i:   599] avg mini-batch loss: 4.728\n",
      "[epoch: 8, i:   699] avg mini-batch loss: 4.692\n",
      "[epoch: 8, i:   799] avg mini-batch loss: 4.695\n",
      "[epoch: 8, i:   899] avg mini-batch loss: 4.726\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 4.682\n",
      "[epoch: 9, i:    99] avg mini-batch loss: 4.672\n",
      "[epoch: 9, i:   199] avg mini-batch loss: 4.642\n",
      "[epoch: 9, i:   299] avg mini-batch loss: 4.661\n",
      "[epoch: 9, i:   399] avg mini-batch loss: 4.626\n",
      "[epoch: 9, i:   499] avg mini-batch loss: 4.642\n",
      "[epoch: 9, i:   599] avg mini-batch loss: 4.613\n",
      "[epoch: 9, i:   699] avg mini-batch loss: 4.605\n",
      "[epoch: 9, i:   799] avg mini-batch loss: 4.598\n",
      "[epoch: 9, i:   899] avg mini-batch loss: 4.616\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 4.596\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 10       # Total epochs.\n",
    "print_freq = 100  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(dataloaders['train'], 0):\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 0 %\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy.\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataloaders['test']):\n",
    "        net.eval()\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
